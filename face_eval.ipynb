{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection Evaluation and Experimentation Notebook\n",
    "Notebook used for experiments and evaluations on the face detection algorithm used in this project.  \n",
    "Currently finds the accuracy and IoU values for every face and frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes an error where \n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataLoader import Train_Loader, Val_Loader\n",
    "from utils import tools\n",
    "from faceDetection.faceDetector import FaceDetection\n",
    "from evaluation import face_evaluate, general_face_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection over Union\n",
    "Code to calculate Intersection over Union values for the faces detected.  \n",
    "Somewhat misleading since we have to resize the frames for face detection to work and bounding boxes for the faces in the annotations/labels are for the original frame before resizing.  \n",
    "We aren't expecting good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IoU(prediction, actual):\n",
    "    '''\n",
    "    Function used to get IoU values for faces detected\n",
    "\n",
    "    Params:\n",
    "        prediction: faces detected using our algorithm\n",
    "        actual: annotation/label for the frame from the csv file\n",
    "\n",
    "    Return: Array of IoU values for each face detected\n",
    "    '''\n",
    "    \n",
    "    ious = []\n",
    "    # Get face bound boxes for the labels\n",
    "    if torch.is_tensor(actual[1]):\n",
    "        a_faces = actual[1].numpy()\n",
    "    else:\n",
    "        a_faces = actual[1]\n",
    "\n",
    "    # If no label is returned for the frame \n",
    "    if len(prediction) == 0:\n",
    "        return [0]\n",
    "\n",
    "    # Evaluates if there is more than one label for the frame\n",
    "    if len(a_faces.shape) > 1:\n",
    "        for i in range(len(a_faces)):\n",
    "            for j in range(len(prediction)):\n",
    "                # Checks if bounding box for face detected is correct\n",
    "                # Then compares the predicted label with the actual label and returns the counts\n",
    "                bound_box = prediction[j][3:7]\n",
    "                if face_evaluate(bound_box, a_faces[i]):\n",
    "                    iou = calculate_IoU(bound_box, a_faces[i])\n",
    "                    ious.append(iou)\n",
    "\n",
    "    # Evaluation for frames with single labels   \n",
    "    else:\n",
    "        for j in range(len(prediction)):\n",
    "            bound_box = prediction[j][3:7]\n",
    "            if face_evaluate(bound_box, a_faces):\n",
    "                iou = calculate_IoU(bound_box, a_faces)\n",
    "                ious.append(iou)\n",
    "\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IoU(predicted, actual):\n",
    "    '''\n",
    "    Function used to calculate the intersection over union (IoU) values for two bounding boxes\n",
    "    Ammended from credit: https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "\n",
    "    Params:\n",
    "        predicted: detected bounding box using our algorithm\n",
    "        actual: Actual bound box found in the labels/annotation\n",
    "    \n",
    "    Return: float IoU value\n",
    "    '''\n",
    "    \n",
    "    x1, y1, x2, y2 = predicted * 300\n",
    "    a_x1, a_y1, a_x2, a_y2 = actual * 300\n",
    "\n",
    "    # Get area of each bounding box\n",
    "    # +1 used to avoid 0 values\n",
    "    predicted_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    actual_area = (a_x2 - a_x1 + 1) * (a_y2 - a_y1 + 1)\n",
    "\n",
    "    # Get coordinates for the intersection box\n",
    "    m_x1 = max(x1, a_x1)\n",
    "    m_x2 = min(x2, a_x2)\n",
    "\n",
    "    m_y1 = max(y1, a_y1)\n",
    "    m_y2 = min(y2, a_y2)\n",
    "\n",
    "    # Calculate intersection and union areas to get IoU\n",
    "    inter = max(0, (m_x2 - m_x1 + 1)) * max(0, (m_y2 - m_y1 + 1))\n",
    "    union = float(predicted_area + actual_area - inter)\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0\n",
    "\n",
    "    iou = inter / union\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Code\n",
    "Code to run the evaluations  \n",
    "Some functions used can be found in the evaluation.py file   \n",
    "Can change videos used by editing the first two lines of the file  \n",
    "Can also change the threshold value for the face detection algorithm which is the probabilty whether a face is detected in the return area  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = ['_mAfwH6i90E', 'B1MAUxpKaV8', '7nHkh4sP5Ks', '2PpxiG0WU18', '-5KQ66BBWC4', '5YPjcdLbs5g', '20TAGRElvfE', '2fwni_Kjf2M']\n",
    "ids = ['B1MAUxpKaV8']\n",
    "threshold = 0.5\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "faces_detected = 0\n",
    "ious = []\n",
    "\n",
    "for video_id in ids:\n",
    "    trainLoader = Train_Loader(video_id=video_id, root_dir=video_id)\n",
    "    trainLoaded = DataLoader(trainLoader, batch_size=64, num_workers=0, shuffle=False)\n",
    "\n",
    "    for images, labels in trainLoaded:\n",
    "        for i in range(len(images)):\n",
    "            actual_label = trainLoader.extract_labels(trainLoader.labels, labels, i)\n",
    "\n",
    "            # Apply Face Detection Algorithm\n",
    "            face_detect = FaceDetection(images[i].numpy(), threshold)\n",
    "            faces = face_detect.detect()\n",
    "            # Get evaluation values -uses function from evaluation file\n",
    "            vid_correct, vid_total = general_face_evaluation(faces, actual_label)\n",
    "            ious.append(get_IoU(faces, actual_label))\n",
    "\n",
    "            correct += vid_correct\n",
    "            total += vid_total\n",
    "            faces_detected += len(faces)\n",
    "\n",
    "    # print(f'------ {ids} ------')\n",
    "    # print(f'Correct: {vid_correct}')\n",
    "    # print(f'Total: {vid_total}')\n",
    "    # print(f'Accuracy: {vid_correct/vid_total}')\n",
    "\n",
    "\n",
    "accuracy = correct / total\n",
    "# Converts md array to 1d\n",
    "ious = list(np.concatenate(ious).flat)\n",
    "\n",
    "print(f'------ Total Face Evaluation ------')\n",
    "print(f'Correct: {correct}')\n",
    "print(f'Total Number of Faces in labels: {total}')\n",
    "print(f'Total Number of Faces Detected:  {faces_detected}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "print(f'\\n------------IoU----------------')     \n",
    "print(f'Mean: {np.mean(ious)}')\n",
    "print(f'Median: {np.median(ious)}')       \n",
    "print(f'Max: {max(ious)}')\n",
    "print(f'Min: {min(ious)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
