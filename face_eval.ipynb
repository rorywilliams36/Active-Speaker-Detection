{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection Evaluation and Experimentation Notebook\n",
    "Notebook used for experiments and evaluations on the face detection algorithm used in this project.  \n",
    "Currently finds the accuracy and IoU values for every face and frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.6.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\roryw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Sometimes an error where \n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataLoader import Train_Loader, Val_Loader\n",
    "from utils import tools\n",
    "from faceDetection.faceDetector import FaceDetection\n",
    "from evaluation import face_evaluate, general_face_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to calculate Intersection over Union values for the faces detected.  \n",
    "Somewhat misleading since we have to resize the frames for face detection to work and bounding boxes for the faces in the annotations/labels are for the original frame before resizing.  \n",
    "We aren't expecting good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IoU(prediction, actual):\n",
    "    '''\n",
    "    Function used to get IoU values for faces detected\n",
    "\n",
    "    Params:\n",
    "        prediction: faces detected using our algorithm\n",
    "        actual: annotation/label for the frame from the csv file\n",
    "\n",
    "    Return: Array of IoU values for each face detected\n",
    "    '''\n",
    "    \n",
    "    ious = []\n",
    "    # Get face bound boxes for the labels\n",
    "    if torch.is_tensor(actual[1]):\n",
    "        a_faces = actual[1].numpy()\n",
    "    else:\n",
    "        a_faces = actual[1]\n",
    "\n",
    "    # If no label is returned for the frame \n",
    "    if len(prediction) == 0:\n",
    "        return [0]\n",
    "\n",
    "    # Evaluates if there is more than one label for the frame\n",
    "    if len(a_faces.shape) > 1:\n",
    "        for i in range(len(a_faces)):\n",
    "            for j in range(len(prediction)):\n",
    "                # Checks if bounding box for face detected is correct\n",
    "                # Then compares the predicted label with the actual label and returns the counts\n",
    "                bound_box = prediction[j][3:7]\n",
    "                if face_evaluate(bound_box, a_faces[i]):\n",
    "                    iou = calculate_IoU(bound_box, a_faces[i])\n",
    "                    ious.append(iou)\n",
    "\n",
    "    # Evaluation for frames with single labels   \n",
    "    else:\n",
    "        for j in range(len(prediction)):\n",
    "            bound_box = prediction[j][3:7]\n",
    "            if face_evaluate(bound_box, a_faces):\n",
    "                iou = calculate_IoU(bound_box, a_faces)\n",
    "                ious.append(iou)\n",
    "\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IoU(predicted, actual):\n",
    "    '''\n",
    "    Function used to calculate the intersection over union (IoU) values for two bounding boxes\n",
    "    Ammended from credit: https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "\n",
    "    Params:\n",
    "        predicted: detected bounding box using our algorithm\n",
    "        actual: Actual bound box found in the labels/annotation\n",
    "    \n",
    "    Return: float IoU value\n",
    "    '''\n",
    "    \n",
    "    x1, y1, x2, y2 = predicted * 300\n",
    "    a_x1, a_y1, a_x2, a_y2 = actual * 300\n",
    "\n",
    "    # Get area of each bounding box\n",
    "    # +1 used to avoid 0 values\n",
    "    predicted_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    actual_area = (a_x2 - a_x1 + 1) * (a_y2 - a_y1 + 1)\n",
    "\n",
    "    # Get coordinates for the intersection box\n",
    "    m_x1 = max(x1, a_x1)\n",
    "    m_x2 = min(x2, a_x2)\n",
    "\n",
    "    m_y1 = max(y1, a_y1)\n",
    "    m_y2 = min(y2, a_y2)\n",
    "\n",
    "    # Calculate intersection and union areas to get IoU\n",
    "    inter = max(0, (m_x2 - m_x1 + 1)) * max(0, (m_y2 - m_y1 + 1))\n",
    "    union = float(predicted_area + actual_area - inter)\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0\n",
    "\n",
    "    iou = inter / union\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to run the evaluations  \n",
    "Can change videos used by editing the first two lines of the file  \n",
    "Can also change the threshold value for the face detection algorithm which is the probabilty whether a face is detected in the return area  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [0.4973851217905868], [0.48897511862673887], [0.45416728675493606], [0.4477696169085551], [0.4299680031253754], [0.44595018089610566], [0.4512906711738147], [0.42918843879569435], [0.5196696624051793], [0.5183120673767778], [0.51494832224455], [0.5088869227365325], [0], [0.5205481110805148], [0.5030713808665859], [0.49023312314179945], [0.485478160624824], [0.4908159839425494], [0.5074944463227572], [0.513865848418206], [0.5044646410359513], [0.5225033574943442], [0.49435439503214557], [0.5179804333261767], [0.5233744396567002], [0.5168800068010752], [0.518130060546311], [0.510960269394233], [0.5097833739740527], [0.5181729946819711], [0.50289568309558], [0.5026302007094664], [0.49476429833467667], [0.4949708536931981], [0.4811016285403097], [0.47181928121068745], [0.472839296163433], [0.4713901237501263], [0.46294222367407034], [0.45701687527605206], [0.5066216184215501], [0.4362500661757752], [0.49973222478114554], [0.5075035299878035], [0.49743590222114414], [0.4893247863068555], [0.4945838979244618], [0], [0], [0], [0], [0], [0], [0], [0], [0.48732149768176924], [0.4724474959790589], [0.46848277852816805], [0.4832585193769385], [0.45294583231837965], [0.42947472135384135], [0.4086939894501194], [0.4164418324481487], [0.5826686690173265], [0.5578333830744765], [0.568890717088084], [0.5400323558052198], [0.5647913952014074], [0.5616230846145261], [0.522604472594048], [0.5339831160383], [0.520902765494738], [0.5222565111689934], [0.5360833418663439], [0.5441937709348498], [0.5716273236396531], [0.5837172874716346], [0.5134312827980875], [0], [0.46660639283143435], [0.5034806694435138], [0.46418577899762475], [0.475488476954418], [0.4918754662167842], [0.5599486961429524], [0.554750321162326], [0.6106548519467214], [0.4620006871005964], [0.5310728893398776], [0.49362552273037574], [0.4964408310040718], [0.5004683182975344], [0.4869776887184199], [0.4603697403683793], [0.4560496508855083], [0.44221280685226], [0.45388535136151753], [0.4576649729717119], [0.48583847346558434], [0.4715967188518014], [0.4979182160985363], [0.44856234648462406], [0.45369282740169387], [0.4837640125024404], [0.4773498134276758], [0.47615667528813443], [0.47980568778318716], [0.5002669282224247], [0.4886134364006261], [0.4831985399493614], [0.4742397939436536], [0.4703055437155477], [0.4798017052885238], [0.4779561138210075], [0.49555765645201993], [0.4838609818483241], [0.4693407006740875], [0.47679408930665307], [0.4759543934287638], [0.4825022419874987], [0.4699586454526618], [0.509616035810115], [0.5051109911506357], [0.46838473325343694], [0.5105023541855489], [0.47499746632427037], [0.524022460765298], [0.49852897660217443], [0.5146013869158731], [0.483057448107423], [0.49203313887242495], [0.5064965382578358]]\n",
      "------ Total Face Evaluation ------\n",
      "Correct: 122\n",
      "Total Number of Faces in labels: 133\n",
      "Total Number of Faces Detected:  122\n",
      "Accuracy: 0.9172932330827067\n",
      "\n",
      "------------IoU----------------\n",
      "Mean: 0.45338569367482245\n",
      "Median: 0.48897511862673887\n",
      "Max: 0.6106548519467214\n",
      "Min: 0.0\n"
     ]
    }
   ],
   "source": [
    "# ids = ['_mAfwH6i90E', 'B1MAUxpKaV8', '7nHkh4sP5Ks', '2PpxiG0WU18', '-5KQ66BBWC4', '5YPjcdLbs5g', '20TAGRElvfE', '2fwni_Kjf2M']\n",
    "ids = ['B1MAUxpKaV8']\n",
    "threshold = 0.5\n",
    "correct = 0\n",
    "total = 0\n",
    "faces_detected = 0\n",
    "ious = []\n",
    "\n",
    "for video_id in ids:\n",
    "    trainLoader = Train_Loader(video_id=video_id, root_dir=video_id)\n",
    "    trainLoaded = DataLoader(trainLoader, batch_size=64, num_workers=0, shuffle=False)\n",
    "\n",
    "    for images, labels in trainLoaded:\n",
    "        for i in range(len(images)):\n",
    "            actual_label = trainLoader.extract_labels(trainLoader.labels, labels, i)\n",
    "\n",
    "            # Apply Face Detection Algorithm\n",
    "            face_detect = FaceDetection(images[i].numpy(), threshold)\n",
    "            faces = face_detect.detect()\n",
    "            \n",
    "            # Get evaluation values\n",
    "            vid_correct, vid_total = general_face_evaluation(faces, actual_label)\n",
    "            ious.append(get_IoU(faces, actual_label))\n",
    "\n",
    "            correct += vid_correct\n",
    "            total += vid_total\n",
    "            faces_detected += len(faces)\n",
    "\n",
    "    # print(f'------ {ids} ------')\n",
    "    # print(f'Correct: {vid_correct}')\n",
    "    # print(f'Total: {vid_total}')\n",
    "    # print(f'Accuracy: {vid_correct/vid_total}')\n",
    "\n",
    "\n",
    "accuracy = correct / total\n",
    "print(ious)\n",
    "ious = list(np.concatenate(ious).flat)\n",
    "\n",
    "print(f'------ Total Face Evaluation ------')\n",
    "print(f'Correct: {correct}')\n",
    "print(f'Total Number of Faces in labels: {total}')\n",
    "print(f'Total Number of Faces Detected:  {faces_detected}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "print(f'\\n------------IoU----------------')     \n",
    "print(f'Mean: {np.mean(ious)}')\n",
    "print(f'Median: {np.median(ious)}')       \n",
    "print(f'Max: {max(ious)}')\n",
    "print(f'Min: {min(ious)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
